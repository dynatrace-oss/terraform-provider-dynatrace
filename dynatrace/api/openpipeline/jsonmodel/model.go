// Package models provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.3.0 DO NOT EDIT.
package jsonmodel

import (
	"encoding/json"

	"github.com/oapi-codegen/runtime"
)

const (
	SsoAuthScopes       = "ssoAuth.Scopes"
	SsoBearerAuthScopes = "ssoBearerAuth.Scopes"
)

// Defines values for AutocompleteSuggestionPartType.
const (
	ASSIGNMENT                      AutocompleteSuggestionPartType = "ASSIGNMENT"
	BOOLEANFALSE                    AutocompleteSuggestionPartType = "BOOLEAN_FALSE"
	BOOLEANTRUE                     AutocompleteSuggestionPartType = "BOOLEAN_TRUE"
	BRACECLOSE                      AutocompleteSuggestionPartType = "BRACE_CLOSE"
	BRACEOPEN                       AutocompleteSuggestionPartType = "BRACE_OPEN"
	BRACKETCLOSE                    AutocompleteSuggestionPartType = "BRACKET_CLOSE"
	BRACKETOPEN                     AutocompleteSuggestionPartType = "BRACKET_OPEN"
	COLON                           AutocompleteSuggestionPartType = "COLON"
	COMMA                           AutocompleteSuggestionPartType = "COMMA"
	COMMANDNAME                     AutocompleteSuggestionPartType = "COMMAND_NAME"
	DATAOBJECT                      AutocompleteSuggestionPartType = "DATA_OBJECT"
	DOT                             AutocompleteSuggestionPartType = "DOT"
	ENDCOMMENT                      AutocompleteSuggestionPartType = "END_COMMENT"
	ENTITYATTRIBUTE                 AutocompleteSuggestionPartType = "ENTITY_ATTRIBUTE"
	ENTITYSELECTORPART              AutocompleteSuggestionPartType = "ENTITY_SELECTOR_PART"
	ENTITYTYPE                      AutocompleteSuggestionPartType = "ENTITY_TYPE"
	FIELDMODIFIER                   AutocompleteSuggestionPartType = "FIELD_MODIFIER"
	FIELDPATTERN                    AutocompleteSuggestionPartType = "FIELD_PATTERN"
	FUNCTIONNAME                    AutocompleteSuggestionPartType = "FUNCTION_NAME"
	INDENT                          AutocompleteSuggestionPartType = "INDENT"
	LINEBREAK                       AutocompleteSuggestionPartType = "LINEBREAK"
	METRICKEY                       AutocompleteSuggestionPartType = "METRIC_KEY"
	NULL                            AutocompleteSuggestionPartType = "NULL"
	NUMBER                          AutocompleteSuggestionPartType = "NUMBER"
	OPERATOR                        AutocompleteSuggestionPartType = "OPERATOR"
	PARAMETERKEY                    AutocompleteSuggestionPartType = "PARAMETER_KEY"
	PARAMETERVALUESCOPE             AutocompleteSuggestionPartType = "PARAMETER_VALUE_SCOPE"
	PARENTHESISCLOSE                AutocompleteSuggestionPartType = "PARENTHESIS_CLOSE"
	PARENTHESISOPEN                 AutocompleteSuggestionPartType = "PARENTHESIS_OPEN"
	PARSEPATTERN                    AutocompleteSuggestionPartType = "PARSE_PATTERN"
	PIPE                            AutocompleteSuggestionPartType = "PIPE"
	QUOTE                           AutocompleteSuggestionPartType = "QUOTE"
	SIMPLEIDENTIFIER                AutocompleteSuggestionPartType = "SIMPLE_IDENTIFIER"
	SINGLEQUOTE                     AutocompleteSuggestionPartType = "SINGLE_QUOTE"
	SLASH                           AutocompleteSuggestionPartType = "SLASH"
	SPACE                           AutocompleteSuggestionPartType = "SPACE"
	STRING                          AutocompleteSuggestionPartType = "STRING"
	TIMESERIESAGGREGATION           AutocompleteSuggestionPartType = "TIMESERIES_AGGREGATION"
	TIMESERIESAGGREGATIONEXPRESSION AutocompleteSuggestionPartType = "TIMESERIES_AGGREGATION_EXPRESSION"
	TIMESTAMPVALUE                  AutocompleteSuggestionPartType = "TIMESTAMP_VALUE"
	TIMEUNIT                        AutocompleteSuggestionPartType = "TIME_UNIT"
	TRAVERSALHOPCOUNT               AutocompleteSuggestionPartType = "TRAVERSAL_HOP_COUNT"
	TRAVERSALOPERATOR               AutocompleteSuggestionPartType = "TRAVERSAL_OPERATOR"
	TRAVERSALRELATIONNAME           AutocompleteSuggestionPartType = "TRAVERSAL_RELATION_NAME"
	UIDVALUE                        AutocompleteSuggestionPartType = "UID_VALUE"
	VARIABLE                        AutocompleteSuggestionPartType = "VARIABLE"
)

// Defines values for ErrorResponseDetailsType.
const (
	ConstraintViolation ErrorResponseDetailsType = "constraintViolation"
)

// Defines values for FieldsExtractionSemantic.
const (
	EXCLUDE    FieldsExtractionSemantic = "EXCLUDE"
	INCLUDE    FieldsExtractionSemantic = "INCLUDE"
	INCLUDEALL FieldsExtractionSemantic = "INCLUDE_ALL"
)

// Defines values for PipelineDefinitionType.
const (
	Classic PipelineDefinitionType = "classic"
	Default PipelineDefinitionType = "default"
)

// Defines values for RoutingType.
const (
	Dynamic RoutingType = "dynamic"
	Static  RoutingType = "static"
)

// Defines values for ValueAssignmentType.
const (
	Constant ValueAssignmentType = "constant"
	Field    ValueAssignmentType = "field"
)

// AutocompleteResponse The response of the autocomplete call.
type AutocompleteResponse struct {
	// Optional True if the suggestions are optional.
	Optional bool `json:"optional"`

	// SuggestedTtlSeconds Suggested duration in seconds, for how long the response may be cached and reused by the client. It is derived from the volatility of the suggestions on the server (if the suggestions are static, how long the server will cache the volatile suggestions, ...). If not provided, then the result may be cached for long time. Value below 1 means that the result should not be cached.
	SuggestedTtlSeconds *int32 `json:"suggestedTtlSeconds,omitempty"`

	// Suggestions The list of suggestions.
	Suggestions []AutocompleteSuggestion `json:"suggestions"`
}

// AutocompleteSuggestion Single suggestion for completion of the query.
type AutocompleteSuggestion struct {
	// AlreadyTypedCharacters Number of characters that the user already typed for this suggestion.
	AlreadyTypedCharacters int32 `json:"alreadyTypedCharacters"`

	// Parts List of suggestion parts.
	Parts []AutocompleteSuggestionPart `json:"parts"`

	// Suggestion The suggested continuation of the input.
	Suggestion string `json:"suggestion"`
}

// AutocompleteSuggestionPart Part of the suggestion.
type AutocompleteSuggestionPart struct {
	// Info The type of the suggestion.
	Info *string `json:"info,omitempty"`

	// Suggestion The suggested continuation of the input.
	Suggestion string `json:"suggestion"`

	// Synopsis The synopsis of the suggestion.
	Synopsis *string `json:"synopsis,omitempty"`

	// Type The type of the autocomplete token.
	Type AutocompleteSuggestionPartType `json:"type"`
}

// AutocompleteSuggestionPartType The type of the autocomplete token.
type AutocompleteSuggestionPartType string

// AzureLogForwardingProcessor Processor to extract a Azure log.
type AzureLogForwardingProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// FieldExtraction Definition of the field extraction.
	FieldExtraction   FieldsExtraction `json:"fieldExtraction"`
	ForwarderConfigId string           `json:"forwarderConfigId"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// BizeventExtractionProcessor Processor to extract a bizevent.
// This processor can only be applied to the logs configuration.
type BizeventExtractionProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// EventProvider Strategy to assign a value.
	EventProvider ValueAssignment `json:"eventProvider"`

	// EventType Strategy to assign a value.
	EventType *ValueAssignment `json:"eventType,omitempty"`

	// FieldExtraction Definition of the field extraction.
	FieldExtraction FieldsExtraction `json:"fieldExtraction"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// BucketAssignmentProcessor Processor to assign a bucket.
type BucketAssignmentProcessor struct {
	// BucketName Bucket that is assigned when the record is matched.
	BucketName string `json:"bucketName"`

	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// Configuration Full configuration containing ingest sources, pipelines and dynamic routing.
type Configuration struct {
	// CustomBasePath The base path for custom ingest endpoints.
	CustomBasePath string `json:"customBasePath"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Endpoints List of all ingest sources of the configuration.
	Endpoints []EndpointDefinition `json:"endpoints"`

	// Id Identifier of the configuration.
	Id string `json:"id"`

	// Pipelines List of all pipelines of the configuration.
	Pipelines []PipelineDefinition `json:"pipelines"`

	// Routing Dynamic routing definition.
	Routing RoutingTable `json:"routing"`

	// Version The current version of the configuration.
	Version string `json:"version"`
}

// ConfigurationListItem Basic information about a configuration.
type ConfigurationListItem struct {
	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Id Identifier of the configuration.
	Id string `json:"id"`
}

// CounterMetricExtractionProcessor Processor to write the occurrences as a metric.
type CounterMetricExtractionProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Dimensions List of unique dimensions to add to the metric.
	Dimensions *[]string `json:"dimensions,omitempty"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// MetricKey The key of the metric to write.
	MetricKey string `json:"metricKey"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// DQLProcessorAutocompleteRequest defines model for DQLProcessorAutocompleteRequest.
type DQLProcessorAutocompleteRequest struct {
	// CursorPosition The position of the cursor inside the script.
	CursorPosition *int32 `json:"cursorPosition,omitempty"`

	// Script The current (in-)complete DQL script.
	Script *string `json:"script,omitempty"`
}

// DQLProcessorVerifyRequest defines model for DQLProcessorVerifyRequest.
type DQLProcessorVerifyRequest struct {
	// Script The unverified DQL script.
	Script *string `json:"script,omitempty"`
}

// DataExtractionStage Data extraction stage configuration of the pipeline.
type DataExtractionStage struct {
	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Processors List of processors.
	Processors []DataExtractionStageProcessor `json:"processors"`
}

// DataExtractionStageProcessor Groups all processors applicable for the DataExtractionStage.
// Applicable processors are DavisEventExtractionProcessor and BizeventExtractionProcessor.
type DataExtractionStageProcessor struct {
	union json.RawMessage
}

// DavisEventExtractionProcessor Processor to extract a davis event.
type DavisEventExtractionProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// Properties List of properties for the extracted davis event.
	Properties []DavisEventProperty `json:"properties"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// DavisEventProperty List of properties for the extracted davis event.
type DavisEventProperty struct {
	// Key The key to set on the davis event.
	Key string `json:"key"`

	// Value The value assigned to the key.
	Value string `json:"value"`
}

// DqlProcessor Processor to apply a DQL script.
type DqlProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// DqlScript The DQL script to apply on the record.
	DqlScript string `json:"dqlScript"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// EndpointDefinition Definition of a single ingest source.
type EndpointDefinition struct {
	// BasePath The base path of the ingest source.
	BasePath string `json:"basePath"`

	// Builtin Indicates if the object is provided by Dynatrace or customer defined.
	Builtin *bool `json:"builtin,omitempty"`

	// DefaultBucket The default bucket assigned to records for the ingest source.
	DefaultBucket *string `json:"defaultBucket,omitempty"`

	// DisplayName Display name of the ingest source.
	DisplayName *string `json:"displayName,omitempty"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Processors The pre-processing done in the ingest source.
	Processors *[]EndpointProcessor `json:"processors,omitempty"`

	// Routing Routing strategy, either dynamic or static.
	Routing Routing `json:"routing"`

	// Segment The segment of the ingest source, which is applied to the base path.
	// Must be unique within a configuration.
	Segment string `json:"segment"`
}

// EndpointProcessor Groups all processors applicable for processing in the EndpointDefinition.
// Applicable processors are DqlProcessor, FieldsAddProcessor, FieldsRemoveProcessor and FieldsRenameProcessor.
type EndpointProcessor struct {
	union json.RawMessage
}

// ErrorResponse Basic information of the encountered error.
type ErrorResponse struct {
	// Code The returned HTTP status code.
	Code int32 `json:"code"`

	// Details Detailed information of the error.
	Details *ErrorResponseDetails `json:"details,omitempty"`

	// Message Description of the encountered error.
	Message string `json:"message"`
}

// ErrorResponseDetails Detailed information of the error.
type ErrorResponseDetails struct {
	// Type Defines the actual set of fields depending on the value. See one of the following objects:
	//
	// * `constraintViolation` -> ConstraintViolationDetails
	Type ErrorResponseDetailsType `json:"type"`
}

// ErrorResponseDetailsType Defines the actual set of fields depending on the value. See one of the following objects:
//
// * `constraintViolation` -> ConstraintViolationDetails
type ErrorResponseDetailsType string

// ErrorResponseEnvelope Encloses the encountered error.
type ErrorResponseEnvelope struct {
	// Error Basic information of the encountered error.
	Error ErrorResponse `json:"error"`
}

// FieldsAddItem List of fields to add to the record.
type FieldsAddItem struct {
	// Name Name of the field.
	Name string `json:"name"`

	// Value Value to assign to the field.
	Value string `json:"value"`
}

// FieldsAddProcessor Processor to add fields.
type FieldsAddProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Fields List of fields to add to the record.
	Fields []FieldsAddItem `json:"fields"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// FieldsExtraction Definition of the field extraction.
type FieldsExtraction struct {
	// Fields Unique fields to include/exclude in the extracted record.
	Fields []string `json:"fields"`

	// Semantic Defines how the fields of the source record should be extracted.
	// INCLUDE: Only the specified fields are extracted.
	// INCLUDE_ALL: All fields are extracted.
	// EXCLUDE: All fields except the specified fields are extracted.
	Semantic FieldsExtractionSemantic `json:"semantic"`
}

// FieldsExtractionSemantic Defines how the fields of the source record should be extracted.
// INCLUDE: Only the specified fields are extracted.
// INCLUDE_ALL: All fields are extracted.
// EXCLUDE: All fields except the specified fields are extracted.
type FieldsExtractionSemantic string

// FieldsRemoveProcessor Processor to remove fields.
type FieldsRemoveProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Fields List of unique fields to remove from the record.
	Fields []string `json:"fields"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// FieldsRenameItem List of fields to rename on the record.
type FieldsRenameItem struct {
	// FromName The field to rename.
	FromName string `json:"fromName"`

	// ToName The new field name.
	ToName string `json:"toName"`
}

// FieldsRenameProcessor Processor to rename fields.
type FieldsRenameProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Fields List of fields to rename on the record.
	Fields []FieldsRenameItem `json:"fields"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// MatcherAutocompleteRequest defines model for MatcherAutocompleteRequest.
type MatcherAutocompleteRequest struct {
	// CursorPosition The position of the cursor inside the query.
	CursorPosition *int32 `json:"cursorPosition,omitempty"`

	// Query The current (in-)complete matcher query.
	Query *string `json:"query,omitempty"`
}

// MatcherRequest defines model for MatcherRequest.
type MatcherRequest struct {
	// Query The matcher query to process.
	Query *string `json:"query,omitempty"`
}

// MetadataNotification The message that provides additional information about the execution of the input string.
type MetadataNotification struct {
	// Arguments The arguments for the message format.
	Arguments *[]string `json:"arguments,omitempty"`

	// Message The complete message of the notification.
	Message *string `json:"message,omitempty"`

	// MessageFormat The message format of the notification, string.format based
	MessageFormat *string `json:"messageFormat,omitempty"`

	// MessageFormatSpecifierTypes The corresponding types for each format specifier used in the error message format.
	MessageFormatSpecifierTypes *[]string `json:"messageFormatSpecifierTypes,omitempty"`

	// NotificationType The notification type.
	NotificationType *string `json:"notificationType,omitempty"`

	// Severity The severity of the notification, currently: INFO, WARN, ERROR.
	Severity *string `json:"severity,omitempty"`

	// SyntaxPosition The position of a token in the input string used for errors and notification to map the message to a specific part of the input.
	SyntaxPosition *TokenPosition `json:"syntaxPosition,omitempty"`
}

// MetricExtractionStage Metric extraction stage configuration of the pipeline.
type MetricExtractionStage struct {
	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Processors List of processors.
	Processors []MetricExtractionStageProcessor `json:"processors"`
}

// MetricExtractionStageProcessor Groups all processors applicable for the MetricExtractionStage.
// Applicable processors are CounterMetricExtractionProcessor and ValueMetricExtractionProcessor.
type MetricExtractionStageProcessor struct {
	union json.RawMessage
}

// NoStorageProcessor Processor to skip storage assignment.
type NoStorageProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// PipelineDefinition Definition of a single pipeline, either 'default' or 'classic'.
type PipelineDefinition struct {
	// Builtin Indicates if the object is provided by Dynatrace or customer defined.
	Builtin *bool `json:"builtin,omitempty"`

	// DataExtraction Data extraction stage configuration of the pipeline.
	DataExtraction *DataExtractionStage `json:"dataExtraction,omitempty"`

	// DisplayName Display name of the pipeline.
	DisplayName *string `json:"displayName,omitempty"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the pipeline.
	Id string `json:"id"`

	// MetricExtraction Metric extraction stage configuration of the pipeline.
	MetricExtraction *MetricExtractionStage `json:"metricExtraction,omitempty"`

	// SecurityContext Security context stage configuration of the pipeline.
	SecurityContext *SecurityContextStage `json:"securityContext,omitempty"`

	// Storage Storage stage configuration of the pipeline.
	Storage *StorageStage `json:"storage,omitempty"`

	// Type Defines the actual set of fields depending on the value. See one of the following objects:
	//
	// * `default` -> DefaultPipelineDefinition
	// * `classic` -> ClassicPipelineDefinition
	Type PipelineDefinitionType `json:"type"`
}

// PipelineDefinitionType Defines the actual set of fields depending on the value. See one of the following objects:
//
// * `default` -> DefaultPipelineDefinition
// * `classic` -> ClassicPipelineDefinition
type PipelineDefinitionType string

// PositionInfo The exact position in the query string.
type PositionInfo struct {
	// Column Input string position column zero based index.
	Column int32 `json:"column"`

	// Index Input string position index.
	Index int32 `json:"index"`

	// Line Input string position line zero based index.
	Line int32 `json:"line"`
}

// PreviewProcessor The processor to execute for the preview. Applicable processors are DqlProcessor, FieldsAddProcessor, FieldsRemoveProcessor, FieldsRenameProcessor and TechnologyProcessor.
type PreviewProcessor struct {
	union json.RawMessage
}

// PreviewProcessorEnvelope defines model for PreviewProcessorEnvelope.
type PreviewProcessorEnvelope struct {
	ConfigId *string `json:"configId,omitempty"`

	// Processor The processor to execute for the preview. Applicable processors are DqlProcessor, FieldsAddProcessor, FieldsRemoveProcessor, FieldsRenameProcessor and TechnologyProcessor.
	Processor PreviewProcessor `json:"processor"`
}

// PreviewProcessorResult defines model for PreviewProcessorResult.
type PreviewProcessorResult struct {
	// Results List of results for each sample data record.
	Results []PreviewProcessorResultEntry `json:"results"`
}

// PreviewProcessorResultEntry Preview result for a single sample data record.
type PreviewProcessorResultEntry struct {
	// Matched Indicates if the record matched the processors matching condition.
	Matched bool `json:"matched"`

	// MatchedProcessors Contains matched processors ids, useful in case of multi-processors preview like in case of Technology.
	MatchedProcessors []string `json:"matchedProcessors"`

	// Record The altered record after the processor was applied.
	Record map[string]interface{} `json:"record"`
}

// Routing Routing strategy, either dynamic or static.
type Routing struct {
	// Type Defines the actual set of fields depending on the value. See one of the following objects:
	//
	// * `static` -> StaticRouting
	// * `dynamic` -> DynamicRouting
	Type RoutingType `json:"type"`
}

// RoutingType Defines the actual set of fields depending on the value. See one of the following objects:
//
// * `static` -> StaticRouting
// * `dynamic` -> DynamicRouting
type RoutingType string

// RoutingTable Dynamic routing definition.
type RoutingTable struct {
	// CatchAllPipeline The default pipeline records are routed into if no dynamic routing entries apply.
	CatchAllPipeline RoutingTableEntryTarget `json:"catchAllPipeline"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Entries List of all dynamic routes.
	Entries []RoutingTableEntry `json:"entries"`
}

// RoutingTableEntry Dynamic routing entry.
type RoutingTableEntry struct {
	// Builtin Indicates if the object is provided by Dynatrace or customer defined.
	Builtin *bool `json:"builtin,omitempty"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// Note Unique note describing the dynamic route.
	Note string `json:"note"`

	// PipelineId Identifier of the pipeline the record is routed into.
	PipelineId string `json:"pipelineId"`
}

// RoutingTableEntryTarget The default pipeline records are routed into if no dynamic routing entries apply.
type RoutingTableEntryTarget struct {
	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// PipelineId Identifier of the pipeline.
	PipelineId string `json:"pipelineId"`
}

// SecurityContextProcessor Processor to set the security context field.
type SecurityContextProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`

	// Value Strategy to assign a value.
	Value ValueAssignment `json:"value"`
}

// SecurityContextStage Security context stage configuration of the pipeline.
type SecurityContextStage struct {
	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Processors List of processors.
	Processors []SecurityContextStageProcessor `json:"processors"`
}

// SecurityContextStageProcessor Groups all processors applicable for the SecurityContextStage.
// Applicable processor is SecurityContextProcessor.
type SecurityContextStageProcessor struct {
	union json.RawMessage
}

// StorageStage Storage stage configuration of the pipeline.
type StorageStage struct {
	// CatchAllBucketName Default bucket assigned to records which do not match any other storage processor.
	CatchAllBucketName string `json:"catchAllBucketName"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Processors List of processors.
	Processors []StorageStageProcessor `json:"processors"`
}

// StorageStageProcessor Groups all processors applicable for the StorageStage.
// Applicable processors are BucketAssignmentProcessor and NoStorageProcessor.
type StorageStageProcessor struct {
	union json.RawMessage
}

// TechnologyProcessor Processor to apply a technology processors.
type TechnologyProcessor struct {
	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`

	// TechnologyId The reference identifier to a specific technology. This technology is applied on the record.
	TechnologyId string `json:"technologyId"`
}

// TokenPosition The position of a token in the input string used for errors and notification to map the message to a specific part of the input.
type TokenPosition struct {
	// End The exact position in the query string.
	End PositionInfo `json:"end"`

	// Start The exact position in the query string.
	Start PositionInfo `json:"start"`
}

// ValueAssignment Strategy to assign a value.
type ValueAssignment struct {
	// Type Defines the actual set of fields depending on the value. See one of the following objects:
	//
	// * `constant` -> ConstantValueAssignment
	// * `field` -> FieldValueAssignment
	Type ValueAssignmentType `json:"type"`
}

// ValueAssignmentType Defines the actual set of fields depending on the value. See one of the following objects:
//
// * `constant` -> ConstantValueAssignment
// * `field` -> FieldValueAssignment
type ValueAssignmentType string

// ValueMetricExtractionProcessor Processor to extract a value from a field as a metric.
type ValueMetricExtractionProcessor struct {
	// Description Name or description of the processor.
	Description string `json:"description"`

	// Dimensions List of unique dimensions to add to the metric.
	Dimensions *[]string `json:"dimensions,omitempty"`

	// Editable Indicates if the user is allowed to edit this object based on permissions and builtin property.
	Editable *bool `json:"editable,omitempty"`

	// Enabled Indicates if the object is active.
	Enabled bool `json:"enabled"`

	// Field The field to extract the value for the metric.
	Field string `json:"field"`

	// Id Identifier of the processor. Must be unique within a stage.
	Id string `json:"id"`

	// Matcher Matching condition to apply on incoming records.
	Matcher string `json:"matcher"`

	// MetricKey The key of the metric to write.
	MetricKey string `json:"metricKey"`

	// SampleData Sample data related to the processor for documentation or testing.
	SampleData *string `json:"sampleData,omitempty"`
}

// VerifyResponse Verify response.
type VerifyResponse struct {
	// Notifications The notifications related to the supplied input string.
	Notifications *[]MetadataNotification `json:"notifications,omitempty"`

	// Valid True if the supplied input string is valid.
	Valid bool `json:"valid"`
}

// UpdateConfigurationByIdApplicationJSONCharsetUTF8RequestBody defines body for UpdateConfigurationById for application/json; charset=utf-8 ContentType.
type UpdateConfigurationByIdApplicationJSONCharsetUTF8RequestBody = Configuration

// DqlProcessorAutocompleteApplicationJSONCharsetUTF8RequestBody defines body for DqlProcessorAutocomplete for application/json; charset=utf-8 ContentType.
type DqlProcessorAutocompleteApplicationJSONCharsetUTF8RequestBody = DQLProcessorAutocompleteRequest

// DqlProcessorVerifyApplicationJSONCharsetUTF8RequestBody defines body for DqlProcessorVerify for application/json; charset=utf-8 ContentType.
type DqlProcessorVerifyApplicationJSONCharsetUTF8RequestBody = DQLProcessorVerifyRequest

// MatcherAutocompleteApplicationJSONCharsetUTF8RequestBody defines body for MatcherAutocomplete for application/json; charset=utf-8 ContentType.
type MatcherAutocompleteApplicationJSONCharsetUTF8RequestBody = MatcherAutocompleteRequest

// MatcherLqlToDqlApplicationJSONCharsetUTF8RequestBody defines body for MatcherLqlToDql for application/json; charset=utf-8 ContentType.
type MatcherLqlToDqlApplicationJSONCharsetUTF8RequestBody = MatcherRequest

// MatcherVerifyApplicationJSONCharsetUTF8RequestBody defines body for MatcherVerify for application/json; charset=utf-8 ContentType.
type MatcherVerifyApplicationJSONCharsetUTF8RequestBody = MatcherRequest

// PreviewSingleApplicationJSONCharsetUTF8RequestBody defines body for PreviewSingle for application/json; charset=utf-8 ContentType.
type PreviewSingleApplicationJSONCharsetUTF8RequestBody = PreviewProcessorEnvelope

// AsDavisEventExtractionProcessor returns the union data inside the DataExtractionStageProcessor as a DavisEventExtractionProcessor
func (t DataExtractionStageProcessor) AsDavisEventExtractionProcessor() (DavisEventExtractionProcessor, error) {
	var body DavisEventExtractionProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDavisEventExtractionProcessor overwrites any union data inside the DataExtractionStageProcessor as the provided DavisEventExtractionProcessor
func (t *DataExtractionStageProcessor) FromDavisEventExtractionProcessor(v DavisEventExtractionProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDavisEventExtractionProcessor performs a merge with any union data inside the DataExtractionStageProcessor, using the provided DavisEventExtractionProcessor
func (t *DataExtractionStageProcessor) MergeDavisEventExtractionProcessor(v DavisEventExtractionProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsBizeventExtractionProcessor returns the union data inside the DataExtractionStageProcessor as a BizeventExtractionProcessor
func (t DataExtractionStageProcessor) AsBizeventExtractionProcessor() (BizeventExtractionProcessor, error) {
	var body BizeventExtractionProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBizeventExtractionProcessor overwrites any union data inside the DataExtractionStageProcessor as the provided BizeventExtractionProcessor
func (t *DataExtractionStageProcessor) FromBizeventExtractionProcessor(v BizeventExtractionProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBizeventExtractionProcessor performs a merge with any union data inside the DataExtractionStageProcessor, using the provided BizeventExtractionProcessor
func (t *DataExtractionStageProcessor) MergeBizeventExtractionProcessor(v BizeventExtractionProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsAzureLogForwardingProcessor returns the union data inside the DataExtractionStageProcessor as a AzureLogForwardingProcessor
func (t DataExtractionStageProcessor) AsAzureLogForwardingProcessor() (AzureLogForwardingProcessor, error) {
	var body AzureLogForwardingProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromAzureLogForwardingProcessor overwrites any union data inside the DataExtractionStageProcessor as the provided AzureLogForwardingProcessor
func (t *DataExtractionStageProcessor) FromAzureLogForwardingProcessor(v AzureLogForwardingProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeAzureLogForwardingProcessor performs a merge with any union data inside the DataExtractionStageProcessor, using the provided AzureLogForwardingProcessor
func (t *DataExtractionStageProcessor) MergeAzureLogForwardingProcessor(v AzureLogForwardingProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t DataExtractionStageProcessor) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *DataExtractionStageProcessor) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDqlProcessor returns the union data inside the EndpointProcessor as a DqlProcessor
func (t EndpointProcessor) AsDqlProcessor() (DqlProcessor, error) {
	var body DqlProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDqlProcessor overwrites any union data inside the EndpointProcessor as the provided DqlProcessor
func (t *EndpointProcessor) FromDqlProcessor(v DqlProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDqlProcessor performs a merge with any union data inside the EndpointProcessor, using the provided DqlProcessor
func (t *EndpointProcessor) MergeDqlProcessor(v DqlProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFieldsAddProcessor returns the union data inside the EndpointProcessor as a FieldsAddProcessor
func (t EndpointProcessor) AsFieldsAddProcessor() (FieldsAddProcessor, error) {
	var body FieldsAddProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFieldsAddProcessor overwrites any union data inside the EndpointProcessor as the provided FieldsAddProcessor
func (t *EndpointProcessor) FromFieldsAddProcessor(v FieldsAddProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFieldsAddProcessor performs a merge with any union data inside the EndpointProcessor, using the provided FieldsAddProcessor
func (t *EndpointProcessor) MergeFieldsAddProcessor(v FieldsAddProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFieldsRemoveProcessor returns the union data inside the EndpointProcessor as a FieldsRemoveProcessor
func (t EndpointProcessor) AsFieldsRemoveProcessor() (FieldsRemoveProcessor, error) {
	var body FieldsRemoveProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFieldsRemoveProcessor overwrites any union data inside the EndpointProcessor as the provided FieldsRemoveProcessor
func (t *EndpointProcessor) FromFieldsRemoveProcessor(v FieldsRemoveProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFieldsRemoveProcessor performs a merge with any union data inside the EndpointProcessor, using the provided FieldsRemoveProcessor
func (t *EndpointProcessor) MergeFieldsRemoveProcessor(v FieldsRemoveProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFieldsRenameProcessor returns the union data inside the EndpointProcessor as a FieldsRenameProcessor
func (t EndpointProcessor) AsFieldsRenameProcessor() (FieldsRenameProcessor, error) {
	var body FieldsRenameProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFieldsRenameProcessor overwrites any union data inside the EndpointProcessor as the provided FieldsRenameProcessor
func (t *EndpointProcessor) FromFieldsRenameProcessor(v FieldsRenameProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFieldsRenameProcessor performs a merge with any union data inside the EndpointProcessor, using the provided FieldsRenameProcessor
func (t *EndpointProcessor) MergeFieldsRenameProcessor(v FieldsRenameProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t EndpointProcessor) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *EndpointProcessor) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsCounterMetricExtractionProcessor returns the union data inside the MetricExtractionStageProcessor as a CounterMetricExtractionProcessor
func (t MetricExtractionStageProcessor) AsCounterMetricExtractionProcessor() (CounterMetricExtractionProcessor, error) {
	var body CounterMetricExtractionProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromCounterMetricExtractionProcessor overwrites any union data inside the MetricExtractionStageProcessor as the provided CounterMetricExtractionProcessor
func (t *MetricExtractionStageProcessor) FromCounterMetricExtractionProcessor(v CounterMetricExtractionProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeCounterMetricExtractionProcessor performs a merge with any union data inside the MetricExtractionStageProcessor, using the provided CounterMetricExtractionProcessor
func (t *MetricExtractionStageProcessor) MergeCounterMetricExtractionProcessor(v CounterMetricExtractionProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsValueMetricExtractionProcessor returns the union data inside the MetricExtractionStageProcessor as a ValueMetricExtractionProcessor
func (t MetricExtractionStageProcessor) AsValueMetricExtractionProcessor() (ValueMetricExtractionProcessor, error) {
	var body ValueMetricExtractionProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromValueMetricExtractionProcessor overwrites any union data inside the MetricExtractionStageProcessor as the provided ValueMetricExtractionProcessor
func (t *MetricExtractionStageProcessor) FromValueMetricExtractionProcessor(v ValueMetricExtractionProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeValueMetricExtractionProcessor performs a merge with any union data inside the MetricExtractionStageProcessor, using the provided ValueMetricExtractionProcessor
func (t *MetricExtractionStageProcessor) MergeValueMetricExtractionProcessor(v ValueMetricExtractionProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t MetricExtractionStageProcessor) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *MetricExtractionStageProcessor) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsDqlProcessor returns the union data inside the PreviewProcessor as a DqlProcessor
func (t PreviewProcessor) AsDqlProcessor() (DqlProcessor, error) {
	var body DqlProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromDqlProcessor overwrites any union data inside the PreviewProcessor as the provided DqlProcessor
func (t *PreviewProcessor) FromDqlProcessor(v DqlProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeDqlProcessor performs a merge with any union data inside the PreviewProcessor, using the provided DqlProcessor
func (t *PreviewProcessor) MergeDqlProcessor(v DqlProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFieldsAddProcessor returns the union data inside the PreviewProcessor as a FieldsAddProcessor
func (t PreviewProcessor) AsFieldsAddProcessor() (FieldsAddProcessor, error) {
	var body FieldsAddProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFieldsAddProcessor overwrites any union data inside the PreviewProcessor as the provided FieldsAddProcessor
func (t *PreviewProcessor) FromFieldsAddProcessor(v FieldsAddProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFieldsAddProcessor performs a merge with any union data inside the PreviewProcessor, using the provided FieldsAddProcessor
func (t *PreviewProcessor) MergeFieldsAddProcessor(v FieldsAddProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFieldsRemoveProcessor returns the union data inside the PreviewProcessor as a FieldsRemoveProcessor
func (t PreviewProcessor) AsFieldsRemoveProcessor() (FieldsRemoveProcessor, error) {
	var body FieldsRemoveProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFieldsRemoveProcessor overwrites any union data inside the PreviewProcessor as the provided FieldsRemoveProcessor
func (t *PreviewProcessor) FromFieldsRemoveProcessor(v FieldsRemoveProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFieldsRemoveProcessor performs a merge with any union data inside the PreviewProcessor, using the provided FieldsRemoveProcessor
func (t *PreviewProcessor) MergeFieldsRemoveProcessor(v FieldsRemoveProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsFieldsRenameProcessor returns the union data inside the PreviewProcessor as a FieldsRenameProcessor
func (t PreviewProcessor) AsFieldsRenameProcessor() (FieldsRenameProcessor, error) {
	var body FieldsRenameProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromFieldsRenameProcessor overwrites any union data inside the PreviewProcessor as the provided FieldsRenameProcessor
func (t *PreviewProcessor) FromFieldsRenameProcessor(v FieldsRenameProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeFieldsRenameProcessor performs a merge with any union data inside the PreviewProcessor, using the provided FieldsRenameProcessor
func (t *PreviewProcessor) MergeFieldsRenameProcessor(v FieldsRenameProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsTechnologyProcessor returns the union data inside the PreviewProcessor as a TechnologyProcessor
func (t PreviewProcessor) AsTechnologyProcessor() (TechnologyProcessor, error) {
	var body TechnologyProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromTechnologyProcessor overwrites any union data inside the PreviewProcessor as the provided TechnologyProcessor
func (t *PreviewProcessor) FromTechnologyProcessor(v TechnologyProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeTechnologyProcessor performs a merge with any union data inside the PreviewProcessor, using the provided TechnologyProcessor
func (t *PreviewProcessor) MergeTechnologyProcessor(v TechnologyProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t PreviewProcessor) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *PreviewProcessor) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsSecurityContextProcessor returns the union data inside the SecurityContextStageProcessor as a SecurityContextProcessor
func (t SecurityContextStageProcessor) AsSecurityContextProcessor() (SecurityContextProcessor, error) {
	var body SecurityContextProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromSecurityContextProcessor overwrites any union data inside the SecurityContextStageProcessor as the provided SecurityContextProcessor
func (t *SecurityContextStageProcessor) FromSecurityContextProcessor(v SecurityContextProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeSecurityContextProcessor performs a merge with any union data inside the SecurityContextStageProcessor, using the provided SecurityContextProcessor
func (t *SecurityContextStageProcessor) MergeSecurityContextProcessor(v SecurityContextProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t SecurityContextStageProcessor) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *SecurityContextStageProcessor) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsBucketAssignmentProcessor returns the union data inside the StorageStageProcessor as a BucketAssignmentProcessor
func (t StorageStageProcessor) AsBucketAssignmentProcessor() (BucketAssignmentProcessor, error) {
	var body BucketAssignmentProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromBucketAssignmentProcessor overwrites any union data inside the StorageStageProcessor as the provided BucketAssignmentProcessor
func (t *StorageStageProcessor) FromBucketAssignmentProcessor(v BucketAssignmentProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeBucketAssignmentProcessor performs a merge with any union data inside the StorageStageProcessor, using the provided BucketAssignmentProcessor
func (t *StorageStageProcessor) MergeBucketAssignmentProcessor(v BucketAssignmentProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsNoStorageProcessor returns the union data inside the StorageStageProcessor as a NoStorageProcessor
func (t StorageStageProcessor) AsNoStorageProcessor() (NoStorageProcessor, error) {
	var body NoStorageProcessor
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromNoStorageProcessor overwrites any union data inside the StorageStageProcessor as the provided NoStorageProcessor
func (t *StorageStageProcessor) FromNoStorageProcessor(v NoStorageProcessor) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeNoStorageProcessor performs a merge with any union data inside the StorageStageProcessor, using the provided NoStorageProcessor
func (t *StorageStageProcessor) MergeNoStorageProcessor(v NoStorageProcessor) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t StorageStageProcessor) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *StorageStageProcessor) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}
